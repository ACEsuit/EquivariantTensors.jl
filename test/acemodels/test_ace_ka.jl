
using LinearAlgebra, Lux, Random, EquivariantTensors, Test, StaticArrays,
      Zygote, ForwardDiff, DecoratedParticles
using ACEbase.Testing: print_tf, println_slim

import EquivariantTensors as ET 
import Polynomials4ML as P4ML      
import KernelAbstractions as KA

include(joinpath(@__DIR__(), "..", "test_utils", "utils_gpu.jl"))

##

module ACEKA

   using LinearAlgebra, Random, Zygote  
   using DecoratedParticles: VState
   import LuxCore: initialparameters, initialstates
   import ChainRulesCore: rrule

   import EquivariantTensors as ET 
   import KernelAbstractions as KA

   struct SimpleACE{T, TR, TY, BB}
      Rnl::TR 
      Ylm::TY
      symbasis::BB    # symmetric basis 
      params::Vector{T}   # model parameters
   end

   initialparameters(rng::AbstractRNG, m::SimpleACE) = 
            (      Rnl = initialparameters(rng, m.Rnl), 
                   Ylm = initialparameters(rng, m.Ylm), 
              symbasis = initialparameters(rng, m.symbasis), 
                params = copy(m.params), )

   initialstates(rng::AbstractRNG, m::SimpleACE) = 
            (      Rnl = initialstates(rng, m.Rnl), 
                   Ylm = initialstates(rng, m.Ylm), 
              symbasis = initialstates(rng, m.symbasis), )

   # ğ”¹ = (#nodes, #features); params = (#features, #readouts)
   # in this toy model, #readouts = 1.

   function eval_basis(model::SimpleACE, X::ET.ETGraph, ps, st) 
      Rnl, _ = model.Rnl(X, ps.Rnl, st.Rnl)
      Ylm, _ = model.Ylm(X, ps.Ylm, st.Ylm)
      (ğ”¹,), _ = ET.ka_evaluate(model.symbasis, Rnl, Ylm, ps.symbasis, st.symbasis)
      return ğ”¹
   end               

   function evaluate(model::SimpleACE, X::ET.ETGraph, ps, st)
      ğ”¹ = eval_basis(model, X, ps, st)
      return ğ”¹ * ps.params, st 
   end

   function jacobian_basis(model::SimpleACE, X::ET.ETGraph, ps, st) 
      (R, _âˆ‚R), _ = ET.evaluate_ed(model.Rnl, X, ps.Rnl, st.Rnl)
      (Y, _âˆ‚Y), _ = ET.evaluate_ed(model.Ylm, X, ps.Ylm, st.Ylm)
      âˆ‚R = VState.( _âˆ‚R )
      âˆ‚Y = VState.( _âˆ‚Y )
      ğ”¹, âˆ‚ğ”¹ = ET._jacobian_X(model.symbasis, R, Y, âˆ‚R, âˆ‚Y)
      return ğ”¹, âˆ‚ğ”¹
   end


   # Semi-manual gradients are still much more efficient 
   #
   function evaluate_with_grad(model::SimpleACE, X::ET.ETGraph, ps, st)
      (Rnl, dRnl), _ = ET.evaluate_ed(model.Rnl, X, ps.Rnl, st.Rnl)
      (Ylm, dYlm), _ = ET.evaluate_ed(model.Ylm, X, ps.Ylm, st.Ylm)

      (ğ”¹,), A, ğ”¸ = ET._ka_evaluate(model.symbasis, Rnl, Ylm, 
                  st.symbasis.aspec, st.symbasis.aaspecs, st.symbasis.A2Bmaps)
      Ï† = ğ”¹ * ps.params

      # let's assume we eventually produce E = âˆ‘Ï† then âˆ‚E = 1, which 
      # backpropagates to âˆ‚Ï† = (1,1,1...)
      # âˆ‚E/âˆ‚ğ”¹ = âˆ‚/âˆ‚ğ”¹ { 1áµ€ ğ”¹ params } = âˆ‚/âˆ‚ğ”¹ { ğ”¹ : 1 âŠ— params}
      âˆ‚ğ”¹ = fill!(similar(ğ”¹, (size(ğ”¹, 1),)), one(eltype(ğ”¹))) * ps.params' 

      # packpropagate through the symmetric basis 
      âˆ‚Rnl, âˆ‚Ylm = ET._ka_pullback((âˆ‚ğ”¹,), model.symbasis, Rnl, Ylm, A, ğ”¸, 
                                    st.symbasis.aspec, st.symbasis.aaspecs, st.symbasis.A2Bmaps)

      # this could be made more memory efficient by avoiding the 
      # many intermediate allocations 
      _grad_R = ET._pullback_edge_embedding(âˆ‚Rnl, VState.(dRnl), X) 
      _grad_Y = ET._pullback_edge_embedding(âˆ‚Ylm, VState.(dYlm), X)

      return Ï†, _grad_R .+ _grad_Y
   end       

end


##
# generate a model 
Dtot = 12   # total degree; specifies the trunction of embeddings and correlations
maxl = 8    # maximum degree of spherical harmonics 
ORD = 3     # correlation-order (body-order = ORD + 1)

# generate the embedding layer 

rbasis = P4ML.ChebBasis(Dtot+1)
rtrans = ET.NTtransform(x -> 1 / (1+norm(x.ğ«)^2))
rembed = ET.EdgeEmbed( ET.EmbedDP(rtrans, rbasis); name = "Rnl" )

ybasis = P4ML.real_solidharmonics(maxl; static=true)
ytrans = ET.NTtransform(x -> x.ğ«)
yembed = ET.EdgeEmbed( ET.EmbedDP(ytrans, ybasis); name = "Ylm" )

mb_spec = ET.sparse_nnll_set(; L = 0, ORD = ORD, 
                  minn = 0, maxn = Dtot, maxl = maxl, 
                  level = bb -> sum((b.n + b.l) for b in bb; init=0), 
                  maxlevel = Dtot)
ğ”¹basis = ET.sparse_equivariant_tensor(; 
            L = 0, mb_spec = mb_spec, 
            Rnl_spec = P4ML.natural_indices(rbasis), 
            Ylm_spec = P4ML.natural_indices(ybasis), 
            basis = real )
Î¸ = randn(Float32, length(ğ”¹basis, 0))

model = ACEKA.SimpleACE(rembed, yembed, ğ”¹basis, Î¸)
_ps, _st = LuxCore.setup(MersenneTwister(1234), model)
ps = ET.float32(_ps); st = ET.float32(_st)

##
# test evaluation 

# 1. generate a random input graph 
nnodes = 30
_X = ET.Testing.rand_graph(nnodes; nneigrg = 5:10)
X = ET.float32(_X)

@info("Basic ETGraph tests")
print_tf(@test ET.nnodes(X) == nnodes)
print_tf(@test ET.maxneigs(X) <= 20)
print_tf(@test ET.nedges(X) == length(X.ii) == length(X.jj) == X.first[end] - 1)
print_tf(@test all( all(X.ii[X.first[i]:X.first[i+1]-1] .== i)
                    for i in 1:nnodes ) )
println()                      

##
# 2. Move model and input to the GPU / Device 
ps_dev = dev(ps)
st_dev = dev(st)
X_dev = dev(X)

@info("Test KA Model Evaluation on CPU and Device")
Ï†, _ = ACEKA.evaluate(model, X, ps, st)
Ï†_dev, _ = ACEKA.evaluate(model, X_dev, ps_dev, st_dev) 
Ï†_dev1 = Array(Ï†_dev)

println_slim(@test Ï† â‰ˆ Ï†_dev1)

## 
# now we try to make the same prediction with the original CPU ace 
# implementation, also skipping the graph datastructure entirely. 

function _basis_env(model::ACEKA.SimpleACE, ğ‘i)
   rij = [ rtrans(x) for x in ğ‘i ]
   Rnl = P4ML.evaluate(rbasis, rij)
   ğ«ij = [ x.ğ« for x in ğ‘i ]
   Ylm = P4ML.evaluate(ybasis, ğ«ij)
   ğ”¹, = ET.evaluate(ğ”¹basis, Rnl, Ylm)   
   return ğ”¹
end

function evaluate_env(model::ACEKA.SimpleACE, ğ‘i)
   ğ”¹ = _basis_env(model, ğ‘i)
   return dot(ğ”¹, Î¸)
end


@info("Test Old Sequential vs KA Evaluation")
Ï†_seq = [ evaluate_env(model, ET.neighbourhood(X, i)[2]) for i in 1:nnodes ]
println_slim(@test Ï† â‰ˆ Ï†_seq â‰ˆ Ï†_dev1) 

##

# semi-hand-written gradient 
# this currently doesn't run on GPU yet -> urgent TODO 
Ï†, âˆ‚X = ACEKA.evaluate_with_grad(model, X, ps, st)


##

@info("Test Differentiation through KA Model Evaluation")

@info("Zygote.gradient") 
energy(model, G, ps, st) = sum(ACEKA.evaluate(model, G, ps, st)[1])
âˆ‡E_zy = Zygote.gradient(G -> energy(model, G, ps, st), X)[1] 

# This requires a fix to P4ML to work properly on the GPU device
# âˆ‡E_zy_dev = Zygote.gradient(G -> energy(model, G, ps_dev, st_dev), X_dev)[1] 


##

@info("ForwardDiff") 

function replace_edges(X, Rmat)
   Rsvec = [ SVector{3}(Rmat[:, i]) for i in 1:size(Rmat, 2) ]
   new_edgedata = [ (; ğ« = ğ«) for ğ« in Rsvec ]
   return ET.ETGraph( X.ii, X.jj, X.first, 
               X.node_data, new_edgedata, X.graph_data, 
               X.maxneigs )
end 

function grad_fd(model, G) 
   function _energy(Rmat)
      G_new = replace_edges(G, Rmat)
      return sum(ACEKA.evaluate(model, G_new, ps, st)[1])
   end
      
   Rsvec = [ x.ğ« for x in G.edge_data ]
   Rmat = reinterpret(reshape, eltype(Rsvec[1]), Rsvec)
   âˆ‡E_fd = ForwardDiff.gradient(_energy, Rmat)
   âˆ‡E_svec = [ SVector{3}(âˆ‡E_fd[:, i]) for i in 1:size(âˆ‡E_fd, 2) ]
   âˆ‡E_edges = [ (; ğ« = ğ«) for ğ« in âˆ‡E_svec ]
   return ET.ETGraph( G.ii, G.jj, G.first, 
               G.node_data, âˆ‡E_edges, G.graph_data, 
               G.maxneigs )
end 

âˆ‡E_fd = grad_fd(model, X)

##

@info("Confirm FD and Zygote agree")
âˆ‡E_zy_ğ« = [ x.ğ« for x in âˆ‡E_zy.edge_data ] 
âˆ‡E_fd_ğ« = [ x.ğ« for x in âˆ‡E_fd.edge_data ]
âˆ‡E_man_ğ« = [ x.ğ« for x in âˆ‚X ]

println_slim(@test all(âˆ‡E_fd_ğ« .â‰ˆ âˆ‡E_zy_ğ« .â‰ˆ âˆ‡E_man_ğ« ))

##

@info("Test Jacobian of basis w.r.t. positions")

# to test the jacobian, we check whether it gives the 
# same as the gradient after contraction with the parameters 
# first we transform it into edge format 

# jacobian as 3-dim tensor 
ğ”¹3, âˆ‚ğ”¹3 = ACEKA.jacobian_basis(model, X, ps, st)

# convert to 2-dimensional tensor (compat with âˆ‡E_zy)
âˆ‚ğ”¹2 = ET.rev_reshape_embedding(âˆ‚ğ”¹3[1], X)
âˆ‚ğ”¹2xÎ¸ = âˆ‚ğ”¹2 * Î¸

println_slim(@test ğ”¹3[1] â‰ˆ ACEKA.eval_basis(model, X, ps, st))
println_slim(@test all(VState.(âˆ‡E_zy.edge_data) .â‰ˆ âˆ‚ğ”¹2xÎ¸)) 

##

# This is reasonably efficient, but would be good to reduce the allocations  
@info("Timings")
println(" Basis: ")
@time ACEKA.eval_basis(model, X, ps, st)
println(" Evaluate with Grad: ")
@time ACEKA.evaluate_with_grad(model, X, ps, st)
println(" Zygote Gradient: ")
@time Zygote.gradient(G -> energy(model, G, ps, st), X)[1] 
println(" Jacobian Basis: ")
@time ACEKA.jacobian_basis(model, X, ps, st)

# This example is a brief demonstration how to build an ACE-like 
# O(3)-invariant model "by hand" (as opposed to via an ML framework)
# Here we use all the utility functions that the ET library offers, 
# whereas in `simple_ace.jl` we do most steps by hand. 

import Polynomials4ML as P4ML 
import EquivariantTensors as ET
using StaticArrays, SparseArrays, Combinatorics, LinearAlgebra, Random

##

# This struct defines a simple ACE-like model. The inputs are a cloud of points
# ğ« = (râ‚, râ‚‚, ..., râ‚™) in 3D space. The output of the model is a scalar that 
# is invariant under rotations, reflections and permutations. 

struct SimpleACE{T, RB, YB, AB, AAB, BB}
   rbasis::RB      # radial embedding Rn
   ybasis::YB      # angular embedding Ylm
   abasis::AB      # atomic basis (pooling of Rn Ylm)
   aabasis::AAB    # n-correlations 
   symm::BB        # symmetrization
   params::Vector{T}   # model parameters
end

function eval_with_grad(m::SimpleACE, ğ«::AbstractVector{<: SVector{3}})
   # evaluate the Rn and Ylm embeddings
   #   Rn[j] = Rn(norm(ğ«[j])), Ylm[j] = Ylm(Rs[j])
   r = norm.(ğ«)
   ğ² = ğ«
   Rn = P4ML.evaluate(m.rbasis, r)
   Ylm = P4ML.evaluate(m.ybasis, ğ²)
   # evaluate the atomic basis:    A_nlm = âˆ‘_j Rn[j] * Ylm[j]
   A = m.abasis((Rn, Ylm))
   # evaluate the n-correlations:  ğ”¸_ğ§ğ¥ğ¦ = âˆ_t A_nâ‚œlâ‚œmâ‚œ
   ğ”¸ = m.aabasis(A)
   # symmetrize the output:        ğ”¹ = C * ğ”¸    
   ğ”¹ = m.symm * ğ”¸
   
   # the model output value is the dot product with the parameters 
   Ï† = dot(m.params, ğ”¹)

   # compute the gradient w.r.t. inputs ğ« in reverse mode
   âˆ‚Ï†_âˆ‚ğ”¹ = m.params 
   âˆ‚Ï†_âˆ‚ğ”¸ = m.symm' * âˆ‚Ï†_âˆ‚ğ”¹
   âˆ‚Ï†_âˆ‚A = ET.pullback(âˆ‚Ï†_âˆ‚ğ”¸, m.aabasis, A)
   âˆ‚Ï†_âˆ‚Rn, âˆ‚Ï†_âˆ‚Ylm = ET.pullback(âˆ‚Ï†_âˆ‚A, m.abasis, (Rn, Ylm))
   âˆ‚Ï†_âˆ‚r = P4ML.pullback(âˆ‚Ï†_âˆ‚Rn, m.rbasis, r)
   âˆ‚Ï†_âˆ‚ğ² = P4ML.pullback(âˆ‚Ï†_âˆ‚Ylm, m.ybasis, ğ²)

   # finally we have to transform the gradient w.r.t. r to a gradient w.r.t. ğ«
   âˆ‡Ï† = [ âˆ‚Ï†_âˆ‚r[j] * (ğ«[j] / r[j]) + âˆ‚Ï†_âˆ‚ğ²[j]   for j = 1:length(ğ«) ]

   return Ï†, âˆ‡Ï†
end


## 
# CONSTRUCTION OF THE ACE MODEL 

# Some model parameters that we will use: 
Dtot = 7   # total degree; specifies the trunction of embeddings and correlations
maxL = 5    # maximum degree of spherical harmonics 
ORD = 3     # correlation-order (body-order = ORD + 1)

##
# [1] first specify the radial and angular embeddings 
rbasis = P4ML.legendre_basis(Dtot+1)
ybasis = P4ML.real_sphericalharmonics(maxL)

##
# [2] Pooling and SparseProduct
# this layer takes the embeddings of the individual particles and pools them 
# to embed the entire set of particles. (point cloud) Note this is a sparse 
# operation; only the basis functions Aâ‚™â‚—â‚˜ are computed for which n + l â‰¤ Dtot.
#
Aspec = [ (n+1, P4ML.lm2idx(l, m)) 
           for n = 0:Dtot for l = 0:maxL for m = -l:l if (n + l <= Dtot) ]
abasis = ET.PooledSparseProduct(Aspec)
@assert abasis.spec == Aspec

##
# [3] n-correlations 
# generating sparse n-correlations is a little more involved, and here is it 
# better to just automate this. But for a very small model we can still do it 
# by hand. 
# first get all possible combinations of A basis functions, then we will filter 
comb1 = with_replacement_combinations(0:length(Aspec), ORD)
ii2bb = ii -> begin 
      bb = [ Aspec[i] for i in ii[ii .> 0]  ];
      nn = Int[b[1]-1 for b in bb]; 
      ll = Int[P4ML.idx2lm(b[2])[1] for b in bb];
      mm = Int[P4ML.idx2lm(b[2])[2] for b in bb];
      return nn, ll, mm 
   end
myfilter = ii -> begin 
      nn, ll, mm = ii2bb(ii);
      return ( (sum(nn + ll; init=0) <= Dtot) &&  # total degree trunction
               iseven(sum(ll; init=0)) &&         # reflection-invariance
               (length(mm) == 0 || ET.O3.m_filter(mm, 0, ET.O3.B_SpheriCart())) &&         # rotation-invariance
               sum(ii) > 0 )           # drop 0-corr sure to bug 
   end 

@show length(comb1)
comb2 = [ ii for ii in comb1 if myfilter(ii) ]
@show length(comb2) 

# notice the incredible reduction in the number of features due to imposing 
# the filters given by the O(3) invariance constraints and the sparsification
# (the latter can be thought of as a smoothness prior)

# to finish the ğ”¸spec we need to convert to 0-corr, 1-corr, 2-corr and 3-corr
# by dropping the zeros from the combinations 
ğ”¸spec = [ filter(!iszero, ii) for ii in comb2 ]
# and now we can finally generate the n-correlations layer 
aabasis = ET.SparseSymmProd(ğ”¸spec)

##
# [4] symmetrization
# the symmetrization operator ğ”¸ â†¦ ğ”¹ = ğ’ â‹… ğ”¸ requires some information about 
# the basis functions that we now have to reconstruct from the specification of 
# the ğ”¸, A, R, Y layers. It basically means rewriting ğ”¸spec in a format that  
# identifies the n, l, m channels. Luckily we already have this in the form of 
# the `ii2bb` function.
nnllmm = [ ii2bb(ii) for ii in ğ”¸spec ]
nice_ğ”¸spec = [
     [ (n = nn[i], l = ll[i], m = mm[i]) for i = 1:length(nn) ] 
     for (nn, ll, mm) in nnllmm ]

symm = ET.symmetrisation_matrix(0, nice_ğ”¸spec; 
                               prune = false, PI = true, basis = real)
numğ”¹ = size(symm, 1)
@show numğ”¹

##
# putting together everything we've construced we can now generate the model 
# here we give the model some random parameters just for testing. 
#
model = SimpleACE(rbasis, ybasis, abasis, aabasis, symm, randn(numğ”¹) )

# we want to check whether the model is invariant under rotations, and whether 
# the gradient is correctly implemented. 

rand_sphere() = ( u = randn(SVector{3, Float64}); u / norm(u) )
rand_x() = (0.1 + 0.9 * rand()) * rand_sphere()
rand_rot() = ( K = @SMatrix randn(3,3); exp(K - K') )

# generate a random configuration of nX points in the unit ball
nX = 7   # number of particles / points 
ğ« = [ rand_x() for _ = 1:nX ]
Q = rand_rot() 
perm = randperm(nX)
Qğ« = Ref(Q) .* ğ«[perm]

Ï†, âˆ‡Ï† = eval_with_grad(model, ğ«)
Ï†Q, âˆ‡Ï†Q = eval_with_grad(model, Qğ«)

# invariance of the model under rotations and permutations
@show Ï† â‰ˆ Ï†Q
# check co-variance of the gradient / forces 
@show Ref(Q) .* âˆ‡Ï†[perm] â‰ˆ âˆ‡Ï†Q

## check correctness of gradients 
# ForwardDiff can handle Vector{SVector}, so we have to work around that 
using ForwardDiff
_2mat(ğ±::AbstractVector{SVector{3, T}}) where {T} = collect(reinterpret(reshape, T, ğ±))
_2vecs(X::AbstractMatrix{T}) where {T} = [ SVector{3, T}(X[:, i]) for i = 1:size(X, 2) ]

F = R -> eval_with_grad(model, _2vecs(R))[1]
âˆ‡F = R -> _2mat(eval_with_grad(model, _2vecs(R))[2])
âˆ‡F_ad = R -> ForwardDiff.gradient(F, R)

R = _2mat(ğ«)
@show âˆ‡F(R) â‰ˆ âˆ‡F_ad(R)

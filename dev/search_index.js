var documenterSearchIndex = {"docs":
[{"location":"api/#Public-API","page":"Public API","title":"Public API","text":"","category":"section"},{"location":"api/","page":"Public API","title":"Public API","text":"EquivariantTensors provides several building blocks for (neural and) tensor networks that preserve various symmetries. These can be combined into various tensor formats from which equivariant parameterized models can be built. ","category":"page"},{"location":"api/#Building-Blocks","page":"Public API","title":"Building Blocks","text":"","category":"section"},{"location":"api/","page":"Public API","title":"Public API","text":"Fused tensor product and pooling PooledSparseProduct\nSparse symmetric product SparseSymmProd","category":"page"},{"location":"api/","page":"Public API","title":"Public API","text":"Evaluating a layer can be done both in-place or allocating, e.g., via ","category":"page"},{"location":"api/","page":"Public API","title":"Public API","text":"abasis::SparseSymmProd\nevaluate!(AA, abasis, A)\nAA = evaluate(abasis, A)","category":"page"},{"location":"api/","page":"Public API","title":"Public API","text":"We refer to the individual documentation for the details of the arguments to each layer. ","category":"page"},{"location":"api/","page":"Public API","title":"Public API","text":"All tensor layers have custom pullbacks implemented that can be accessed via non-allocating or allocating calls, e.g., ","category":"page"},{"location":"api/","page":"Public API","title":"Public API","text":"pullback!(‚àÇAA, ‚àÇA, abasis, A)\n‚àÇAA = pullback(‚àÇA, abasis, A)","category":"page"},{"location":"api/","page":"Public API","title":"Public API","text":"Pushforwards and reverse-over-reverse are implemented using ForwardDiff. This is quasi-optimal even for reverse-over-reverse due to the fact that it can be interpreted as a directional derivative on evaluate and pullback (after swapping derivatives). As a matter of fact, we generally recommend to not use these directly. ChainRules integration would give an easier use-pattern. For optimal performance the same technique should be applied to an entire model architecture rather than to each individual layer. This would avoid several unnecessary intermediate allocations.","category":"page"},{"location":"api/","page":"Public API","title":"Public API","text":"The syntax for pushforwards is straightforward:","category":"page"},{"location":"api/","page":"Public API","title":"Public API","text":"pushforward!(P, ‚àÇP, layer, X, ‚àÇX)\nP, ‚àÇP = pushforward(layer, X, ‚àÇX)","category":"page"},{"location":"api/","page":"Public API","title":"Public API","text":"For second-order pullbacks the syntax is ","category":"page"},{"location":"api/","page":"Public API","title":"Public API","text":"pullback2!(‚àá_‚àÇP, ‚àá_X, ‚àÇ‚àÇX, ‚àÇP, layer, X)\n‚àá_‚àÇP, ‚àá_X = pullback2(‚àÇ‚àÇX, ‚àÇP, layer, X)","category":"page"},{"location":"api/#Bumper-and-WithAlloc-usage","page":"Public API","title":"Bumper and WithAlloc usage","text":"","category":"section"},{"location":"api/","page":"Public API","title":"Public API","text":"Using the WithAlloc.jl interface the api can be used conveniently as follows (always from within a @no_escape block)","category":"page"},{"location":"api/","page":"Public API","title":"Public API","text":"A = @withalloc evaluate!(abasis, BB)\n‚àÇX = @withalloc pullback!(‚àÇP, layer, X)\nP, ‚àÇP = @withalloc pushforward!(layer, X, ‚àÇX)","category":"page"},{"location":"api/#Lie-Group-Symmetrization-/-Coupling-Operators","page":"Public API","title":"Lie Group Symmetrization / Coupling Operators","text":"","category":"section"},{"location":"api/","page":"Public API","title":"Public API","text":"Construct coupling coefficients: O3.coupling_coeffs","category":"page"},{"location":"api/","page":"Public API","title":"Public API","text":"(TODO: detailed description)","category":"page"},{"location":"api/#Pre-built-Equivariant-Tensors","page":"Public API","title":"Pre-built Equivariant Tensors","text":"","category":"section"},{"location":"benchmarking/#Benchmarking-Instructions","page":"Benchmarking","title":"Benchmarking Instructions","text":"","category":"section"},{"location":"benchmarking/","page":"Benchmarking","title":"Benchmarking","text":"For general reference see BenchmarkTools.jl manual.","category":"page"},{"location":"benchmarking/","page":"Benchmarking","title":"Benchmarking","text":"A simple way to run benchmarks is to call","category":"page"},{"location":"benchmarking/","page":"Benchmarking","title":"Benchmarking","text":"using BenchmarkTools\nusing PkgBenchmark\nusing EquivariantTensors\n\nbench = benchmarkpkg(EquivariantTensors)\nresults = bench.benchmarkgroup\n\n# You can search with macro \"@tagged\"\nresults[@tagged \"derivative\" && \"Chebyshev\"]","category":"page"},{"location":"benchmarking/","page":"Benchmarking","title":"Benchmarking","text":"You can create BenchmarkConfig to control benchmark","category":"page"},{"location":"benchmarking/","page":"Benchmarking","title":"Benchmarking","text":"t2 = BenchmarkConfig(env = Dict(\"JULIA_NUM_THREADS\" => 2))\nbench_t2 = benchmarkpkg(EquivariantTensors, t2)","category":"page"},{"location":"benchmarking/","page":"Benchmarking","title":"Benchmarking","text":"Benchmarks can be saved to a file with","category":"page"},{"location":"benchmarking/","page":"Benchmarking","title":"Benchmarking","text":"export_markdown(\"results.md\", bench)","category":"page"},{"location":"benchmarking/","page":"Benchmarking","title":"Benchmarking","text":"Comparing current branch to another branch","category":"page"},{"location":"benchmarking/","page":"Benchmarking","title":"Benchmarking","text":"# current branch to \"origin/main\"\nj = judge(EquivariantTensors, \"origin/main\")","category":"page"},{"location":"benchmarking/","page":"Benchmarking","title":"Benchmarking","text":"Benchmark scaling to different number of threads","category":"page"},{"location":"benchmarking/","page":"Benchmarking","title":"Benchmarking","text":"t4 = BenchmarkConfig(env = Dict(\"JULIA_NUM_THREADS\" => 4))\nt8 = BenchmarkConfig(env = Dict(\"JULIA_NUM_THREADS\" => 8))\n\n# Compare how much changing from 4-threads to 8 improves the performance\nj = judge(EquivariantTensors, t8, t4)\n\nshow(j.benchmarkgroup)","category":"page"},{"location":"benchmarking/#CI-Benchmarks","page":"Benchmarking","title":"CI Benchmarks","text":"","category":"section"},{"location":"benchmarking/","page":"Benchmarking","title":"Benchmarking","text":"Benchmarks can be run automatically on PR's by adding label \"run benchmark\" to the PR.","category":"page"},{"location":"benchmarking/#Adding-more-benchmarks","page":"Benchmarking","title":"Adding more benchmarks","text":"","category":"section"},{"location":"benchmarking/","page":"Benchmarking","title":"Benchmarking","text":"Take a look at benchmark/benchmarks.jl for an example. If your benchmark depends on additional packages you need to add the package to benchmark/Project.toml.","category":"page"},{"location":"#EquivariantTensors","page":"Home","title":"EquivariantTensors","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"These pages contain the documentation for EquivariantTensors. This package provides tools to construct equivariant tensor layers to be used in equivariant models, as well as computational kernels to evaluate those layers.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The package is a work in progress. The plan is that it becomes the backend for several ACEsuit packages such as ACEpotentials.jl and ACEhamiltonians.jl.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The documentation is very rudimentary for now. We suggest to look at the tests, inline docs and the examples.","category":"page"},{"location":"docstrings/#Docstrings","page":"Docstrings","title":"Docstrings","text":"","category":"section"},{"location":"docstrings/","page":"Docstrings","title":"Docstrings","text":"This page lists all docstrings in EquivariantTensors.jl including for functions that are not part of the public API. Please check with the Public API for which functionality we aim to guarantee semver-stability.","category":"page"},{"location":"docstrings/","page":"Docstrings","title":"Docstrings","text":"","category":"page"},{"location":"docstrings/#EquivariantTensors.Envelope","page":"Docstrings","title":"EquivariantTensors.Envelope","text":"To be used as part of TransformedBasis as follows: \n\ny = transform(x) \nP = basis(y) * envelope(x, y)\n\nWarning: P may be modified in-place!\n\n\n\n\n\n","category":"type"},{"location":"docstrings/#EquivariantTensors.NTtransform","page":"Docstrings","title":"EquivariantTensors.NTtransform","text":"If a particle x is represented as a NamedTuple, e.g., x = (r = SA[...], Z = 13) then an NTtransform can be used to embed this named tuple into ‚Ñù in a differentiable  way, e.g., \n\nx = (ùê´ = randn(StaticVector{3, Float64}), Z = rand(10:50))\nr0 = Float64[ ... ]  # list of r0 values for rescaling r \ntrans = NTtransform(x -> 1 / (1 + norm(x.ùê´)/r0[x.Z]))\n\nWe can then evaluate and differenitate \n\ny = evaluate(trans, x, ps, st)\ny, dy = evaluate_ed(trans, x, ps, st)\n\nHere, dy is again a named-tuple with the derivative w.r.t. x.ùê´ stored as  dy.ùê´. The derivative w.r.t. Z is not taken because Z is a categorical variable.\n\n\n\n\n\n","category":"type"},{"location":"docstrings/#EquivariantTensors.ParallelEmbed","page":"Docstrings","title":"EquivariantTensors.ParallelEmbed","text":"struct ParallelEmbed : basically a variation on Lux.Parallel,  but makes some assumptions on what the individual layers to  be evaluated in parallel do to enable some simple optimizations. \n\nThe assumption is that each layer is a \"basis\", i.e. a mapping x -> B(x),  where x is low-dimensional and B(x) is moderate-dimensional. This means that  the optimal differentiation is in forward-mode. This is exploited by  implementing the functions evaluate and evaluate_ed. For implementing  models that use ParallelEmbed a forward-pass that also differentiates  (e.g. energy and forces) is implemented with evaluate_ed. \n\n\n\n\n\n","category":"type"},{"location":"docstrings/#EquivariantTensors.PooledSparseProduct","page":"Docstrings","title":"EquivariantTensors.PooledSparseProduct","text":"struct PooledSparseProduct :  This implements a fused (tensor) product and pooling operation. Suppose  we are given N embeddings phi^(i)_k_i then the pooled sparse product  generates feature vectors of the form \n\nA_k_1 dots k_N = sum_j prod_t = 1^N phi^(t)_k_t(x_j)\n\nwhere x_j are an list of inputs (multi-set). \n\nThe canonical example is \n\nA_nlm = sum_j R_nl(r_j mu_j) Y_l^m( hatbm r_j )\n\nwhere R_nl is a radial embedding, possibly depending on a categorical  variable mu_j and Y_l^m are spherical harmonics. \n\nConstructor\n\nPooledSparseProduct(spec)\n\nwhere spec is a list of (k_1 dots k_N) tuples or vectors, or  AbstractMatrix where each column specifies such a tuple. \n\n\n\n\n\n","category":"type"},{"location":"docstrings/#EquivariantTensors.SelectLinL","page":"Docstrings","title":"EquivariantTensors.SelectLinL","text":"struct SelectLinL <: AbstractLuxLayer\n\nA Lux layer which acts as a simple linear layer, but using a categorical  variable to select a weight matrix:\n\n   P -> W[x] * P \n\nThis layer is experimental and likely very inefficient. \n\n\n\n\n\n","category":"type"},{"location":"docstrings/#EquivariantTensors.SparseMatCSX","page":"Docstrings","title":"EquivariantTensors.SparseMatCSX","text":"struct SparseMatCSX\n\nSparse matrix format that is stored in both CSR and CSC, and can be transferred  to GPU devices. Matrix multiplication via KernelAbstractions.jl for GPU support and uses whichever format (CSR, CSC) is most suitable for a given operation. \n\n\n\n\n\n","category":"type"},{"location":"docstrings/#EquivariantTensors.SparseSymmProd","page":"Docstrings","title":"EquivariantTensors.SparseSymmProd","text":"SparseSymmProd : sparse symmetric product with entries stored as tuples.  Input is a vector A; each entry of the output vector AA is of the form \n\n bm A_i_1 dots i_N = prod_t = 1^N A_i_t\n\nConstructor\n\nSparseSymmProd(spec)\n\nwhere spec is a list of tuples or vectors, each of which specifies an AA basis function as described above. For example, \n\nspec = [ (1,), (2,), (1,1), (1,2), (2,2), \n         (1,1,1), (1,1,2), (1,2,2), (2,2,2) ]\nbasis = SparseSymmProd(spec)         \n\ndefines a basis of 9 functions, \n\n A_1 A_2 A_1^2 A_1 A_2 A_2^2 A_1^3 A_1^2 A_2 A_1 A_2^2 A_2^3 \n\n\n\n\n\n","category":"type"},{"location":"docstrings/#EquivariantTensors.TransformedBasis","page":"Docstrings","title":"EquivariantTensors.TransformedBasis","text":"struct TransformedBasis\n\nBasically a three-stage chain, consisting of an input transformation,  and basis evaluation. Constructor: \n\nTransformedBasis(; transin, basis, transout)\n\ndefaults for transin and transout are IDtrans(), i.e. identity  transformations.\n\nThe layer performs the following chain: \n\ny = evaluate(transin, x, ...)\nP = evaluate(basis, y, ...) \nB = evaluate(transout, P, x, ...)\n\nIt is assumed that transout only utilizes the categorical variables stored in \n\nx but not the continuous variables. This means that when differentiating,  one only needs to differentiate B(P(y), x) with respect to y but not  with respect to x.\n\nit is also assumed that basis has no parameters \n\n\n\n\n\n","category":"type"},{"location":"docstrings/#EquivariantTensors._auto_Rnl_spec-Tuple{Any}","page":"Docstrings","title":"EquivariantTensors._auto_Rnl_spec","text":"Takes a list of ùî∏ or ùîπ specifications (many-body) in the form of \n\n   [  [(n=., l=., m=.), (n=., l=., m=.)], ... ]\n\nand converts it into a list of sorted unique (n=., l=.) named pairs,  i.e the specification of the one-body basis. \n\n\n\n\n\n","category":"method"},{"location":"docstrings/#EquivariantTensors._auto_Ylm_spec-Tuple{Any, Any}","page":"Docstrings","title":"EquivariantTensors._auto_Ylm_spec","text":"autoYlmspec(mbspec) \n\ntakes a list of ùî∏ or ùîπ specifications (many-body) and return the specification  of the Ylm basis functions as a [ (l = ., m = .), ... ] list. \n\n\n\n\n\n","category":"method"},{"location":"docstrings/#EquivariantTensors._auto_nnllmm_spec-Tuple{Any}","page":"Docstrings","title":"EquivariantTensors._auto_nnllmm_spec","text":"takes an nnll spec and generates a complete list of all possible nnllmm\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#EquivariantTensors._make_idx_AA_spec-Tuple{Any, Any}","page":"Docstrings","title":"EquivariantTensors._make_idx_AA_spec","text":"convert readable AA_spec into the internal representation of the AA basis\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#EquivariantTensors._make_idx_A_spec-Tuple{Any, Vector{@NamedTuple{n::Int64}}, Any}","page":"Docstrings","title":"EquivariantTensors._make_idx_A_spec","text":"convert readable A_spec into the internal representation of the A basis\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#EquivariantTensors.invmap","page":"Docstrings","title":"EquivariantTensors.invmap","text":"  invmap(a::AbstractVector)\n\nReturns a structure that makes looking up the index of an element in a vector  convenient and fast. Assumes that elements of a are unique.\n\ninva = invmap(a) \ninva[a[i]] == i  # true for all i\n\n\n\n\n\n","category":"function"},{"location":"docstrings/#EquivariantTensors.reshape_embedding-Tuple{Any, EquivariantTensors.ETGraph}","page":"Docstrings","title":"EquivariantTensors.reshape_embedding","text":"reshape_embedding(P, ii, jj, nnodes, maxneigs)\n\nTakes a Nedges x Nfeat matrix and writes it into a 3-dimensional array of  size (maxneigs, nnodes, Nfeat) where each column corresponds to a node.  The \"missing\" neighbours are filled with zeros.\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#EquivariantTensors.rev_reshape_embedding-Tuple{Any, EquivariantTensors.ETGraph}","page":"Docstrings","title":"EquivariantTensors.rev_reshape_embedding","text":"revreshapeembedding(P3, ii, jj, nnodes, maxneigs) -> P\n\nReverse operation for reshape_embedding. P3 is of shape  (maxneigs, nnodes, nfeatures), and this gets written into P which is  of shape (nedges, nfeatures) and then returned. \n\n\n\n\n\n","category":"method"},{"location":"docstrings/#EquivariantTensors.setproduct-Tuple{Any}","page":"Docstrings","title":"EquivariantTensors.setproduct","text":"setproduct(A)\n\nAssumes the A is a length-N collection of collections. It returns a  P = Matrix{T} where each P[i, :] is a vector of length N with P[i, j] ‚àà A[j]. The number of columns of P is the number of such  products, i.e. prod(length.(A)).\n\nIn constrast with Iterators.product this implementation  is type-stable for a priori unknown N.\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#EquivariantTensors.sparse_equivariant_tensor-Tuple{}","page":"Docstrings","title":"EquivariantTensors.sparse_equivariant_tensor","text":"sparseequivarianttensor(L, mbspec, Rnlspec, Ylm_spec, basis)\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#EquivariantTensors.sparse_product-Tuple{}","page":"Docstrings","title":"EquivariantTensors.sparse_product","text":"sparse_product(...) : utility function to generate high-dimensional sparse grids which are downsets. All arguments are keyword arguments (with defaults):\n\nNU : maximum correlation order\nminvv = 0 : minvv[i] gives the minimum value forvv[i]`\nmaxvv = Inf : maxvv[i] gives the minimum value forvv[i]`\ntup2bb = vv -> vv :\nadmissible = _ -> false : determines whether a tuple belongs to the downset\nfilter = _ -> true : a callable object that returns true of tuple is to be kept and\n\nfalse otherwise (whether or not it is part of the downset!) This is used, e.g. to enfore conditions such as ‚àë l‚Çê = even or |‚àë m‚Çê| ‚â¶ M\n\nordered = false : whether only ordered tuples are produced; ordered tuples\n\ncorrespond to  permutation-invariant basis functions\n\n\n\n\n\n","category":"method"},{"location":"docstrings/#EquivariantTensors.symmetrisation_matrix-Tuple{Integer, Any}","page":"Docstrings","title":"EquivariantTensors.symmetrisation_matrix","text":"symmetrisationmatrix(L, mbspec; prune, kwargs...) -> ùî∏2ùîπ, ùî∏_spec\n\nGenerates the symmetrization operator for a sparse ACE basis. The basis is \n\nspecified via the input mb_spec, which is a list of basis function\n\nspecifications of the form \n\nmb_spec = [ [(n=0, l=0), (n=1, l=0)], [(n=1, l=1), (n=2, l=1)], ... ] \n\ni.e. a Vector{Vector{NL}}. where NL = @NamedTuple{n::Int, l::Int}.\n\nThe parameter L determines the order of the ouput, e.g. L=0 for an invariant  scalar, L = 1 for a vector, and so forth. \n\nThe output is given in terms of a sparse matrix ùî∏2ùîπ in CCS format and a  specification of the ùî∏ basis as a Vector{Vector{NLM}} where  NLM = @NamedTuple{n::Int, l::Int, m::Int}. \n\n\n\n\n\n","category":"method"},{"location":"docstrings/#EquivariantTensors.O3.TYVec2CartMat","page":"Docstrings","title":"EquivariantTensors.O3.TYVec2CartMat","text":"struct TYVec2CartMat \n\ntransformation from a real Y vector to a cartesian matrix; accepts as input  either an SVector{3}(i.e. the Y_1^m) or aSYYVector(containing both  the Y_0^0 and Y_1^m); the output is aSMatrix{3,3}`.\n\n\n\n\n\n","category":"type"},{"location":"docstrings/#EquivariantTensors.O3.TYVec2CartVec","page":"Docstrings","title":"EquivariantTensors.O3.TYVec2CartVec","text":"struct TYVec2CartVec \n\ntransformation from a real Y vector to a cartesian vector; accepts as input  either an SVector{3}(i.e. the Y_1^m) or aSYYVector(containing both  the Y_0^0 and Y_1^m); the output is aSVector{3}`.\n\n\n\n\n\n","category":"type"},{"location":"docstrings/#EquivariantTensors.O3.TYVec2YMat","page":"Docstrings","title":"EquivariantTensors.O3.TYVec2YMat","text":"struct TYVec2YMat\n\ntransformation from a real Y vector to a spherical matrix       \n\n\n\n\n\n","category":"type"},{"location":"docstrings/#EquivariantTensors.O3.D_from_angles-Tuple{Integer, AbstractVector{<:Real}, typeof(real)}","page":"Docstrings","title":"EquivariantTensors.O3.D_from_angles","text":"Dfromangles(l, Œ∏, basis)\n\nHere, l::Integer and Œ∏ a 3-element vector or tuple, basis must be either  real or complex. Output is a Wigner-D matrix such that y ‚àò Q = D * y  with y real/complex spherical harmonics. \n\n\n\n\n\n","category":"method"},{"location":"docstrings/#EquivariantTensors.O3.QD_from_angles-Tuple{Integer, AbstractVector{<:Real}, Any}","page":"Docstrings","title":"EquivariantTensors.O3.QD_from_angles","text":"produces a rotation Q and Wigner-D matrix D such that y ‚àò Q = D * y with y real spherical harmonics. \n\n\n\n\n\n","category":"method"},{"location":"docstrings/#EquivariantTensors.O3.coupling_coeffs","page":"Docstrings","title":"EquivariantTensors.O3.coupling_coeffs","text":"O3.coupling_coeffs(L, ll, nn; PI, basis)\nO3.coupling_coeffs(L, ll; PI, basis)\n\nCompute coupling coefficients for the spherical harmonics basis, where \n\nL must be an Integer;\nll, nn must be vectors or tuples of Integer of the same length.\nPI: whether or not the coupled basis is permutation-invariant (or the \n\ncorresponding tensor symmetric); default is true when nn is provided  and false when nn is not provided.\n\nbasis: which basis is being coupled, default is complex, alternative\n\nchoice is real, which is compatible with the SpheriCart.jl convention.  \n\n\n\n\n\n","category":"function"}]
}

# ----------------------------------------------- 
# simple example embedding layer for radial and angular embeddings 
# to be replaced asap with a generic implementation. 
struct RnlYlmEmbedding{TTR, TBR, TTY, TBY}
   transr::TTR 
   rbasis::TBR 
   transy::TTY
   ybasis::TBY
end

initialparameters(rng::AbstractRNG, emb::RnlYlmEmbedding) = 
      (rbasis = NamedTuple(), ybasis = NamedTuple())

initialstates(rng::AbstractRNG, emb::RnlYlmEmbedding) = 
      (rbasis = NamedTuple(), ybasis = NamedTuple())

function evaluate(emb::RnlYlmEmbedding, X::ETGraph, ps, st)
   # Evaluate the radial and angular embeddings for the graph
   r = map(ğ« -> emb.transr(ğ«), X.edge_data)
   Rnl = evaluate(emb.rbasis, r)
   RÌ‚ = map(ğ« -> ğ« / norm(ğ«), X.edge_data)
   Ylm = evaluate(emb.ybasis, RÌ‚)

   # Reshape the embeddings into a 3D array format
   Rnl_3 = reshape_embedding(Rnl, X)
   Ylm_3 = reshape_embedding(Ylm, X)

   return (Rnl_3, Ylm_3), st 
end 


function ka_pullback(âˆ‚Rnl_3, âˆ‚Ylm_3, emb::RnlYlmEmbedding, 
                     X::ETGraph, ps, st)
   # (re-)evaluate the radial and angular embeddings, now with 
   # derivatives to prepare for computing the pullback 
   r = map(ğ« -> emb.transr(ğ«), X.edge_data)
   âˆ‡r = map(ğ« -> ForwardDiff.gradient(emb.transr, ğ«), X.edge_data)
   Rnl, dRnl = evaluate_ed(emb.rbasis, r)

   RÌ‚ = map(ğ« -> ğ« / norm(ğ«), X.edge_data)
   Ylm, dYlm = evaluate_ed(emb.ybasis, RÌ‚)

   âˆ‚Rnl = rev_reshape_embedding(âˆ‚Rnl_3, X)
   âˆ‚Ylm = rev_reshape_embedding(âˆ‚Ylm_3, X)

   # TODO: here I am assuming that edge_data is just a collection of 
   #       relative positions. This needs to be suitably generalized. 
   âˆ‚ğ«_r = similar(X.edge_data)
   fill!(âˆ‚ğ«_r, zero(eltype(âˆ‚ğ«_r)))
   âˆ‚ğ«_y = similar(X.edge_data)
   fill!(âˆ‚ğ«_y, zero(eltype(âˆ‚ğ«_y)))

   # âˆ‡_ğ«[a] {âˆ‚Rnl : Rnl} 
   #   = âˆ‡_ğ«[a] { âˆ‘_a,k âˆ‚Rnl[a,k] * Rnl[a,k] } 
   #   = âˆ‘_k âˆ‚Rnl[a,k] âˆ‡_ğ«[a] Rnl[a,k]
   #   = { âˆ‘_k âˆ‚Rnl[a,k] dRnl[a,k] } * âˆ‡ğ«[a]
   
   @kernel function _pb_Rnl!(âˆ‚ğ«, @Const(âˆ‚Rnl), @Const(dRnl), @Const(âˆ‡r))
      a = @index(Global)
      nfeats = size(dRnl, 2)
      t = âˆ‚Rnl[a, 1] * dRnl[a, 1] 
      for k = 2:nfeats 
         t += âˆ‚Rnl[a, k] * dRnl[a, k]
      end
      âˆ‚ğ«[a] = t * âˆ‡r[a] 
      nothing 
   end

   @kernel function _pb_Ylm!(âˆ‚ğ«, @Const(âˆ‚Ylm), @Const(dYlm), 
                                 @Const(RÌ‚), @Const(r))
      a = @index(Global)
      nfeats = size(dYlm, 2)
      t = âˆ‚Ylm[a, 1] * dYlm[a, 1]  # â„ * â„Â³ â†’ â„Â³
      for k = 2:nfeats
         t += âˆ‚Ylm[a, k] * dYlm[a, k] 
      end 
      ğ«Ì‚_a = RÌ‚[a] 
      âˆ‚ğ«[a] = t + ğ«Ì‚_a * (sum(ğ«Ì‚_a .* t) / r[a])
      nothing 
   end

   nedg = nedges(X)
   backend = KernelAbstractions.get_backend(âˆ‚Rnl)
   
   kernel_pb_Rnl! = _pb_Rnl!(backend)
   kernel_pb_Rnl!(âˆ‚ğ«_r, âˆ‚Rnl, dRnl, âˆ‡r; ndrange = (nedg,))

   kernel_pb_Ylm! = _pb_Ylm!(backend)
   kernel_pb_Ylm!(âˆ‚ğ«_r, âˆ‚Ylm, dYlm, RÌ‚, r; ndrange = (nedg,))

   synchronize(backend)
   âˆ‚ğ« = âˆ‚ğ«_r + âˆ‚ğ«_y

   return âˆ‚ğ«, st 
end

